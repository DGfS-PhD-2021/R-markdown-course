@article{Johnson-Laird1989,
author = {Johnson-Laird, Philip Nicholas and Oatley, Keith},
issn = {0269-9931},
journal = {Cognition and emotion},
number = {2},
pages = {81--123},
publisher = {Taylor {\&} Francis},
title = {{The language of emotions: An analysis of a semantic field}},
volume = {3},
year = {1989}
}
@incollection{Mellmann2017,
abstract = {Wie bringt man Emotionen in Texte? Emotionen sind zun{\"{a}}chst ein psychisches Ph{\"{a}}nomen, also eine Eigenschaft des Lesers oder des Autors und keine Texteigenschaft. Trotzdem haben wir den Eindruck, dass Texte aufgrund ihrer objektiven Beschaffenheit einen bestimmten Grad an emotionaler Intensit{\"{a}}t aufweisen. Dies liegt daran, dass wir bestimmte Texteigenschaften mit emotionaler Bedeutung belegen. Schwierig wird der Sachverhalt dadurch, dass wir offenbar nicht nur in der expliziten Erw{\"{a}}hnung von Emotionen (z. B. wenn es {\"{u}}ber eine literarische Figur hei{\ss}t, sie sei eifers{\"{u}}chtig) eine emotionale Semantik erkennen, sondern auch in einer Reihe anderer Texteigenschaften, die aufgrund ihrer Verarbeitung durch den Rezipienten von ihm als ›emotional‹ wahrgenommen werden. Solche gleichsam impliziten emotionalen Bedeutungsgehalte setzen rezipientenseitige Konstruktionsprozesse voraus, die {\"{u}}ber die blo{\ss}e Decodierung sprachlicher Zeichen hinausgehen.},
address = {Stuttgart},
author = {Mellmann, Katja},
doi = {10.1007/978-3-476-05364-0_36},
editor = {Mart{\'{i}}nez, Mat{\'{i}}as},
isbn = {978-3-476-05364-0},
pages = {243--249},
publisher = {J.B. Metzler},
title = {{Emotionalisieren BT  - Erz{\"{a}}hlen: Ein interdisziplin{\"{a}}res Handbuch}},
url = {https://doi.org/10.1007/978-3-476-05364-0{\_}36},
year = {2017}
}
@article{Kleinberg2020,
author = {Kleinberg, Bennett},
journal = {arXiv preprint arXiv:2006.08952},
title = {{Manipulating emotions for ground truth emotion analysis}},
year = {2020}
}
@article{Jockers2015,
author = {Jockers, Matthew L and Underwood, Ted},
journal = {A new companion to digital humanities},
pages = {291--306},
publisher = {Wiley Online Library},
title = {{Text‐mining the humanities}},
year = {2015}
}
@book{Archer2016,
abstract = {"What if there was an algorithm that could predict which novels become mega-bestsellers? Are books like Dan Brown's The Da Vinci Code and Gillian Flynn's Gone Girl the Gladwellian outliers of publishing? The Bestseller Code boldly claims that the New York Times bestsellers in fiction are predictable and that it's possible to know with 97{\%} certainty if a manuscript is likely to hit number one on the list as opposed to numbers two through fifteen. The algorithm does exist; the code has been cracked; the results are in; and they are stunning. The system analyzes themes, plot, character, pacing, even the frequency of words and punctuation, to predict which stories will resonate with readers. A 28-year-old heroine is a big plus. So is realism. Giving 30{\%} of your novel to only two specific topics. And if you can include a dog rather than a cat and few sex scenes, you have a better chance of writing a bestselling novel. The project is an investigation into our intellectual and emotional responses as humans and readers to books of all genres. It is a big idea book that will appeal to fans of The Black Swan by Nassim Taleb, a book for data-mining nerds, as well as a book about writing, reading, and publishing. Anyone who has ever wondered why Gone Girl, Girl on the Train or The Girl With the Dragon Tattoo captured so many readers worldwide will find their interest piqued"-- CN  - Z1033.B3 A73 2016},
address = {New York},
author = {Archer, Jodie and Jockers, Matthew Lee},
edition = {First edit},
isbn = {978-1-250-08827-7},
keywords = {Authorship,BUSINESS {\&} ECONOMICS / Industries / Media {\&} Commun,Best sellers,Books and reading,COMPUTERS / Information Theory,Fiction,LANGUAGE ARTS {\&} DISCIPLINES / Publishing,LITERARY CRITICISM / Books {\&} Reading,Popular literature,Publishers and publishing,United States},
pages = {242},
publisher = {St. Martin's Press},
title = {{The bestseller code: anatomy of the blockbuster novel}},
year = {2016}
}
@article{Jockers2010,
abstract = {We compare and benchmark the performance of five classification methods, four of which are taken from the machine learning literature, in a classic authorship attribution problem involving the Federalist Papers. Cross-validation results are reported for each method, and each method is further employed in classifying the disputed papers and the few papers that are generally understood to be coauthored. These tests are performed using two separate feature sets: a “raw” feature set containing all words and word bigrams that are common to all of the authors, and a second “pre-processed” feature set derived by reducing the raw feature set to include only words meeting a minimum relative frequency threshold. Each of the methods tested performed well, but nearest shrunken centroids and regularized discriminant analysis had the best overall performances with 0/70 cross-validation errors.},
author = {Jockers, Matthew L and Witten, Daniela M},
doi = {10.1093/llc/fqq001},
issn = {0268-1145},
journal = {Literary and Linguistic Computing},
month = {jun},
number = {2},
pages = {215--223},
title = {{A comparative study of machine learning methods for authorship attribution}},
url = {https://doi.org/10.1093/llc/fqq001},
volume = {25},
year = {2010}
}
@book{Ekman1994,
author = {Ekman, Paul Ed and Davidson, Richard J},
isbn = {019508943X},
publisher = {Oxford University Press},
title = {{The nature of emotion: Fundamental questions.}},
year = {1994}
}
@article{Ekman2004,
author = {Ekman, Paul},
issn = {1756-1833},
journal = {Bmj},
number = {Suppl S5},
publisher = {British Medical Journal Publishing Group},
title = {{Emotions revealed}},
volume = {328},
year = {2004}
}
@book{Erli2014,
abstract = {In nineteenth-century Germany, breakthroughs in printing technology and an increasingly literate populace led to an unprecedented print production boom that has long presented scholars with a challenge: how to read it all? This anthology seeks new answers to the scholarly quandary of the abundance of text. Responding to Franco Moretti's call for "distant reading" and modeling a range of innovative approaches to literary-historical analysis informed by theburgeoning field of digital humanities, it asks what happens when we shift our focus from the one to the many, from the work to the network. The thirteen essays in this volume explore the evolving concept of "distant reading" and its application to the analysis of German literature and culture in the long nineteenth century. The contributors consider how new digital technologies enable both the testing of hypotheses and the discovery of patterns and trends, as well as how "distant" and traditional "close" reading can complement each another in hybrid models of analysis that maintain careful attention to detail, but also make calculation, enumeration, and empirical descriptioncritical elements of interpretation. Contributors: Kirsten Belgum, Tobias Boes, Matt Erlin, Fotis Jannidis and Gerhard Lauer, Lutz Koepnick, Todd Kontje, Peter M. McIsaac, Katja Mellmann, Nicolas Pethes, Andrew Piper and Mark Algee-Hewitt, Allen Beye Riddell, Lynne Tatlock, Paul A. Youngman and Ted Carmichael. Matt Erlin is Professor of German and Chair of the Department of Germanic Languages and Literatures, and Lynne Tatlock is Hortense and Tobias Lewin Distinguished Professor in the Humanities, both at Washington University, St. Louis.},
doi = {DOI:},
editor = {Erlin, Matt and Tatlock, Lynne},
isbn = {9781571135391},
publisher = {Boydell {\&} Brewer},
title = {{Distant Readings: Topologies of German Culture in the Long Nineteenth Century}},
url = {https://www.cambridge.org/core/books/distant-readings/B3451E599C6FBF717F025C79575E00D0},
year = {2014}
}
